---
title: "eXplainable AI?"
date: "2019-08-05"
---

Appréhendant un possible nouvel "hiver" susceptible de venir geler les retombées économiques de l'intelligence artificielle, les [philanthropes](https://www.pwc.com/gx/en/about/purpose-and-values.html) de PricewaterhouseCoopers [proposent une piste](https://www.pwc.co.uk/audit-assurance/assets/explainable-ai.pdf) pour sauver ce marché dynamique.

Le problème : le public voudrait être bien sûr que l'IA, oracle aux voies impénétrables, prend ses décisions en accord avec les "principes éthique de base", et les executive managers exigeraient un "bouclier" contre les éventuelles conséquences "inattendues" des algorithmes et leurs possibles conséquences en terme de "réputation".

Bref, pour sauver la promesse d'un gain de PNB de 15 000 milliards de dollars d'ici à 2030, PwC recommande d'investir dans une Intelligence Artificielle capable d'expliquer ses décisions.

Mais que veut dire expliquer ?

![](https://blog.atlant.is/wp-content/uploads/2019/08/cheshire.jpg)

On pourrait argumenter que la force du _machine learning_ et autres _deep neural networks_, comparés aux anciens systèmes à base de règles, est de ne pas être contraints à définir leur processus de décision par le truchement de la parole et des mots. Autrement dit : ne pas être contraints à être explicables. En effet, on conçoit bien qu'un réseau neuronal [comportant plusieurs dizaines de milliards de paramètres numériques](https://arxiv.org/pdf/1701.06538.pdf) ne puisse pas être facilement compressé en un texte, même long de quelques milliers de pages.

Donc, que veut dire expliquer ? S'agit-il, comme le ferait un mathématicien, de compléter l'éclair initial intuitif et créateur par une preuve rigoureuse et analytique ? D'utiliser notre cerveau _lent_ pour confirmer la trouvaille de notre cerveau _rapide_ ? (cf _[Thinking, Fast and Slow](https://www.youtube.com/watch?v=CjVQJdIrDJ0)_, Daniel Kahneman).

La réalité est sûrement plus mercantile. Il n'est pas question de démontrer la vérité mais plutôt de "construire la confiance", c'est à dire fabriquer le consentement. Entre les lignes, on comprend qu'il s'agit au mieux de vulgariser (permettre au public de "comprendre en gros comment les variables en entrée influent sur le résultat en sortie"), au pire de manipuler : en même temps que fournir une décision, fournir les éléments de langage pour la faire avaler par le public.

Et on peut imaginer un futur radieux où l'IA au service de la politique de quelques uns proposerait à la fois les textes législatifs et la com' assurant le service après-vente. Bref, libérer les énergies et aplanir les obstacles à l'avénement de la douce promesse à 15 000 milliards de dollars.

Would somebody please throw a wrench into the works?
